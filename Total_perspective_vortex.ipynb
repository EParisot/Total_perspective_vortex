{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in c:\\users\\rock_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\rock_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mne) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\rock_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mne) (1.6.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\rock_\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "mne.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Rock_\\Desktop\\Projects\\Total_perspective_vortex\\data\\S001\\S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from C:\\Users\\Rock_\\Desktop\\Projects\\Total_perspective_vortex\\data\\S001\\S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from C:\\Users\\Rock_\\Desktop\\Projects\\Total_perspective_vortex\\data\\S001\\S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data\"\n",
    "subjects = [1] # 1 indexed\n",
    "#runs = [5, 9, 13] # hands versus foots imaginary\n",
    "runs = [6, 10, 14] # hands versus foots real\n",
    "\n",
    "\n",
    "raw_fnames = {}\n",
    "for i, d in enumerate(os.listdir(data_dir)):\n",
    "    if os.path.isdir(os.path.join(data_dir, d)) and i + 1 in subjects:\n",
    "        raw_fnames[d] = os.listdir(os.path.join(data_dir, d))\n",
    "\n",
    "dataset = []\n",
    "sfreq = None\n",
    "for d in raw_fnames:\n",
    "    subject = []\n",
    "    b = False\n",
    "    for i, f in enumerate(raw_fnames[d]):\n",
    "        if f.endswith(\".edf\") and int(f.split('R')[1].split(\".\")[0]) in runs:\n",
    "            subject_data = mne.io.read_raw_edf(os.path.join(data_dir, d, f), preload=True)\n",
    "            if sfreq == None:\n",
    "                sfreq = subject_data.info[\"sfreq\"]\n",
    "            if subject_data.info[\"sfreq\"] == sfreq:\n",
    "                subject.append(subject_data)\n",
    "            else:\n",
    "                b = True\n",
    "                break\n",
    "    if b:\n",
    "        continue\n",
    "    dataset.append(mne.concatenate_raws(subject))\n",
    "dataset = mne.concatenate_raws(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawEDF | S001R06.edf, 64 x 60000 (375.0 s), ~29.4 MB, data loaded>\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fc5., Fc3., Fc1., Fcz., Fc2., Fc4., Fc6., C5.., C3.., C1.., ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 80.0 Hz\n",
      " meas_date: 2009-08-12 16:15:00 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 160.0 Hz\n",
      ">\n",
      "['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n",
      "<Annotations | 94 segments: BAD boundary (2), EDGE boundary (2), T0 (45), ...>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset.info)\n",
    "print(dataset.info[\"ch_names\"])\n",
    "# events\n",
    "print(dataset.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dots from channel's names\n",
    "dataset = dataset.rename_channels(lambda s: s.strip(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        <td>August 12, 2009  16:15:00 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>67 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 64 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>160.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>80.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>S001R06.edf, S001R10.edf, S001R14.edf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:06:14 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEDF | S001R06.edf, 64 x 60000 (375.0 s), ~29.4 MB, data loaded>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set montage\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "\n",
    "eegbci.standardize(dataset)  # set channel names\n",
    "dataset.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=1\n",
      "    Range : 0 ... 0 =      0.000 ...     0.000 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "montage = dataset.get_montage()\n",
    "p = montage.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "# plot data\n",
    "p = mne.viz.plot_raw(dataset, scalings={\"eeg\": 75e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FirWin filter\n",
    "dataset_tmp = dataset.copy()\n",
    "# set montage again since its is not copyed\n",
    "dataset_tmp.set_montage(montage)\n",
    "dataset_tmp.filter(7, 30, fir_design='firwin', skip_by_annotation='edge')\n",
    "filtered_dataset = dataset_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "# plot data\n",
    "p = mne.viz.plot_raw(filtered_dataset, scalings={\"eeg\": 75e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 45 events and 801 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((45, 64, 801),\n",
       " array([1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_id = dict(T1=0, T2=1)\n",
    "# avoid classification of evoked responses by using epochs that start 1s after cue onset.\n",
    "tmin, tmax = -1., 4.\n",
    "\n",
    "events, _ = mne.events_from_annotations(filtered_dataset, event_id=event_id)\n",
    "picks = mne.pick_types(filtered_dataset.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "epochs = mne.Epochs(filtered_dataset, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)   \n",
    "labels = epochs.events[:, -1]\n",
    "epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "labels_train = epochs_train.events[:, -1]\n",
    "epochs.get_data().shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mne.decoding import CSP\n",
    "from CSP import CSP\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from mne.decoding import UnsupervisedSpatialFilter, Vectorizer, Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mne.tools/stable/auto_examples/decoding/decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-decoding-csp-eeg-py\n",
    "\n",
    "Subject 1, runs 6, 10, 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 64, 801) (45,)\n",
      "Classification accuracy: 0.933333 / Chance level: 0.533333\n"
     ]
    }
   ],
   "source": [
    "# Define a cross-validation generator (reduce variance):\n",
    "epochs_data = epochs.get_data()\n",
    "epochs_data_train = epochs_train.get_data()\n",
    "\n",
    "print(epochs_data.shape, labels.shape)\n",
    "\n",
    "n_splits = 5  # how many folds to use for cross-validation\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "#cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assemble a classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "#csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "csp = CSP(4)\n",
    "sca = Scaler(epochs.info)\n",
    "\n",
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "clf = Pipeline([('SCA', sca), ('CSP', csp), ('LDA', lda)])\n",
    "clf = clf.fit(epochs_data_train, labels)\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "\n",
    "# plot CSP patterns estimated on full data for visualization\n",
    "#csp.fit_transform(epochs_data, labels)\n",
    "#p = csp.plot_patterns(epochs.info, ch_type='eeg', units='Patterns (AU)', size=1.5)\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == 0)\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window settings=  80 16 [  0  16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272\n",
      " 288 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560\n",
      " 576 592 608 624 640 656 672 688 704 720]\n",
      "(45, 64, 801)\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 0 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 0 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 0 1 0 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 0 0 0 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 0 1 0 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 0 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 0 0 0 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 0 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 0 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 0 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 0 1 1 0 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 0 1 1 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 0 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 0 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 0 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 0 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 0 1 0 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 0 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 0 0]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 0 0]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 1 0]\n",
      "(9, 64, 80)\n",
      "[0 1 0 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[0 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 0 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 0 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 1 1]\n",
      "(9, 64, 80)\n",
      "[1 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "w_length = int(sfreq * 0.5)   # running classifier: window length\n",
    "w_step = int(sfreq * 0.1)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "\n",
    "print(\"window settings= \", w_length, w_step, w_start)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "print(epochs_data.shape)\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data_train, labels_train):\n",
    "    # get batch labels\n",
    "    y_train, y_test = labels_train[train_idx], labels_train[test_idx]\n",
    "    # fit the csp and get transformed data for test and train\n",
    "    X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "    X_test = csp.transform(epochs_data_train[test_idx])\n",
    "    \n",
    "    # fit classifier on transformed data\n",
    "    lda.fit(X_train, y_train)\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        print(epochs_data[test_idx][:, :, n:(n + w_length)].shape)\n",
    "        X_test = csp.transform(epochs_data[test_idx][:, :, n:(n + w_length)])\n",
    "        score_this_window.append(lda.score(X_test, y_test))\n",
    "        print(clf.predict(epochs_data[test_idx][:, :, n:(n + w_length)]))\n",
    "    scores_windows.append(score_this_window)\n",
    "\n",
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.) / sfreq + epochs.tmin\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(w_times, np.mean(scores_windows, 0), label='Score')\n",
    "plt.axvline(0, linestyle='--', color='k', label='Onset')\n",
    "plt.axhline(0.5, linestyle='-', color='k', label='Chance')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('classification accuracy')\n",
    "plt.title('Classification score over time')\n",
    "plt.legend(loc='lower right')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpler Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mne.tools/0.19/auto_tutorials/machine-learning/plot_sensors_decoding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a cross-validation generator (reduce variance):\n",
    "X = epochs.get_data()\n",
    "X_train = epochs_train.get_data()\n",
    "y = labels\n",
    "\n",
    "print(epochs_data.shape)\n",
    "\n",
    "n_splits = 5  # how many folds to use for cross-validation\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "#cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assemble a classifier\n",
    "sca = Scaler(epochs.info)\n",
    "pca = UnsupervisedSpatialFilter(PCA(n_components=4), average=False)\n",
    "vec = Vectorizer()\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "clf = Pipeline([(\"SCA\", sca), (\"PCA\", pca), (\"VEC\", vec), ('LR', lr)])\n",
    "scores = cross_val_score(clf, X_train, y, cv=cv, n_jobs=1)\n",
    "print(scores)\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == 0)\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "X = epochs.get_data()\n",
    "X_train = epochs_train.get_data()\n",
    "y = labels\n",
    "\n",
    "# We will train the classifier on all left visual vs auditory trials on MEG\n",
    "\n",
    "clf = Pipeline([(\"SCA\", StandardScaler()), (\"LR\", LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc', verbose=True)\n",
    "scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs.times, scores, label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
