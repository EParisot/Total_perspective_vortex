{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in c:\\users\\rock_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\rock_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mne) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\rock_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mne) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "mne.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Rock_\\Desktop\\Projects\\Total_perspective_vortex\\data\\S001\\S001R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from C:\\Users\\Rock_\\Desktop\\Projects\\Total_perspective_vortex\\data\\S001\\S001R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from C:\\Users\\Rock_\\Desktop\\Projects\\Total_perspective_vortex\\data\\S001\\S001R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data\"\n",
    "subjects = [1] # 1 indexed\n",
    "runs = [5, 9, 13] # hands versus foots real\n",
    "#runs = [6, 10, 14] # hands versus foots imaginary\n",
    "#runs = [3, 7, 11] # left vs right fist real\n",
    "#runs = [4, 8, 12] # left vs right fist imaginary\n",
    "\n",
    "\n",
    "raw_fnames = {}\n",
    "for i, d in enumerate(os.listdir(data_dir)):\n",
    "    if os.path.isdir(os.path.join(data_dir, d)) and i + 1 in subjects:\n",
    "        raw_fnames[d] = os.listdir(os.path.join(data_dir, d))\n",
    "\n",
    "dataset = []\n",
    "sfreq = None\n",
    "for d in raw_fnames:\n",
    "    subject = []\n",
    "    b = False\n",
    "    for i, f in enumerate(raw_fnames[d]):\n",
    "        if f.endswith(\".edf\") and int(f.split('R')[1].split(\".\")[0]) in runs:\n",
    "            subject_data = mne.io.read_raw_edf(os.path.join(data_dir, d, f), preload=True)\n",
    "            if sfreq == None:\n",
    "                sfreq = subject_data.info[\"sfreq\"]\n",
    "            if subject_data.info[\"sfreq\"] == sfreq:\n",
    "                subject.append(subject_data)\n",
    "            else:\n",
    "                b = True\n",
    "                break\n",
    "    if b:\n",
    "        continue\n",
    "    dataset.append(mne.concatenate_raws(subject))\n",
    "dataset = mne.concatenate_raws(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawEDF | S001R05.edf, 64 x 60000 (375.0 s), ~29.4 MB, data loaded>\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fc5., Fc3., Fc1., Fcz., Fc2., Fc4., Fc6., C5.., C3.., C1.., ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 80.0 Hz\n",
      " meas_date: 2009-08-12 16:15:00 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 160.0 Hz\n",
      ">\n",
      "['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n",
      "<Annotations | 94 segments: BAD boundary (2), EDGE boundary (2), T0 (45), ...>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset.info)\n",
    "print(dataset.info[\"ch_names\"])\n",
    "# events\n",
    "print(dataset.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dots from channel's names\n",
    "dataset = dataset.rename_channels(lambda s: s.strip(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        <td>August 12, 2009  16:15:00 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>67 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 64 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>160.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>80.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>S001R05.edf, S001R09.edf, S001R13.edf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:06:14 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEDF | S001R05.edf, 64 x 60000 (375.0 s), ~29.4 MB, data loaded>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set montage\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "\n",
    "eegbci.standardize(dataset)  # set channel names\n",
    "dataset.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=1\n",
      "    Range : 0 ... 0 =      0.000 ...     0.000 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "montage = dataset.get_montage()\n",
    "p = montage.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "p = mne.viz.plot_raw(dataset, scalings={\"eeg\": 75e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FirWin filter\n",
    "dataset_tmp = dataset.copy()\n",
    "# set montage again since its is not copyed\n",
    "dataset_tmp.set_montage(montage)\n",
    "dataset_tmp.filter(7, 30, fir_design='firwin', skip_by_annotation='edge')\n",
    "filtered_dataset = dataset_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "p = mne.viz.plot_raw(filtered_dataset, scalings={\"eeg\": 75e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 45 events and 801 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((45, 64, 801),\n",
       " array([1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "        1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_id = dict(T1=0, T2=1)\n",
    "# avoid classification of evoked responses by using epochs that start 1s after cue onset.\n",
    "tmin, tmax = -1., 4.\n",
    "\n",
    "events, _ = mne.events_from_annotations(filtered_dataset, event_id=event_id)\n",
    "picks = mne.pick_types(filtered_dataset.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "epochs = mne.Epochs(filtered_dataset, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)   \n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "epochs.get_data().shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from mne.decoding import UnsupervisedSpatialFilter, Vectorizer, Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mne.tools/stable/auto_examples/decoding/decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-decoding-csp-eeg-py\n",
    "\n",
    "Subject 1, runs 6, 10, 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 64, 801) (45,)\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9e+02 (2.2e-16 eps * 64 dim * 1.3e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.3e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.7e+02 (2.2e-16 eps * 64 dim * 1.2e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2e+02 (2.2e-16 eps * 64 dim * 1.4e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.6e+02 (2.2e-16 eps * 64 dim * 1.1e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2e+02 (2.2e-16 eps * 64 dim * 1.4e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.5e+02 (2.2e-16 eps * 64 dim * 1.1e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.1e+02 (2.2e-16 eps * 64 dim * 1.5e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9e+02 (2.2e-16 eps * 64 dim * 1.3e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.3e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.2e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.3e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.6e+02 (2.2e-16 eps * 64 dim * 1.1e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.1e+02 (2.2e-16 eps * 64 dim * 1.4e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2e+02 (2.2e-16 eps * 64 dim * 1.4e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.6e+02 (2.2e-16 eps * 64 dim * 1.1e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.3e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.2e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2e+02 (2.2e-16 eps * 64 dim * 1.4e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.7e+02 (2.2e-16 eps * 64 dim * 1.2e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Test Classification accuracy: 0.921739 / Chance level: 0.511111\n",
      "[1.         0.86956522 0.91304348 0.7826087  0.95652174 0.86956522\n",
      " 0.95652174 0.95652174 0.91304348 1.        ]\n"
     ]
    }
   ],
   "source": [
    "epochs_data = epochs.get_data()\n",
    "\n",
    "print(epochs_data.shape, labels.shape)\n",
    "\n",
    "n_splits = 5  # how many folds to use for cross-validation\n",
    "#cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "cv = ShuffleSplit(10, test_size=0.5, random_state=42)\n",
    "\n",
    "# Assemble a classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "csp = CSP(n_components=3, reg=None, log=True, norm_trace=False)\n",
    "sca = Scaler(epochs.info)\n",
    "\n",
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "clf = Pipeline([('SCA', sca), ('CSP', csp), ('LDA', lda)])\n",
    "\n",
    "#train\n",
    "scores = cross_val_score(clf, epochs_data, labels, cv=cv, n_jobs=1)\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == 0)\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Test Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training (Train datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.3e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e+02 (2.2e-16 eps * 64 dim * 1.2e+16  max singular value)\n",
      "    Estimated rank (mag): 64\n",
      "    MAG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "pivot = int(0.5 * len(epochs_data))\n",
    "\n",
    "clf = clf.fit(epochs_data[:pivot], labels[:pivot])\n",
    "p = clf.named_steps[\"CSP\"].plot_patterns(epochs.info, ch_type='eeg', units='Patterns (AU)', size=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Classification (Test datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape=  (23, 64, 801) y shape=  (23,)\n",
      "n= 0 pred=  [1] truth=  [1]\n",
      "n= 1 pred=  [1] truth=  [0]\n",
      "n= 2 pred=  [1] truth=  [1]\n",
      "n= 3 pred=  [0] truth=  [0]\n",
      "n= 4 pred=  [1] truth=  [1]\n",
      "n= 5 pred=  [1] truth=  [1]\n",
      "n= 6 pred=  [0] truth=  [0]\n",
      "n= 7 pred=  [1] truth=  [0]\n",
      "n= 8 pred=  [0] truth=  [0]\n",
      "n= 9 pred=  [1] truth=  [1]\n",
      "n= 10 pred=  [0] truth=  [0]\n",
      "n= 11 pred=  [1] truth=  [1]\n",
      "n= 12 pred=  [1] truth=  [1]\n",
      "n= 13 pred=  [0] truth=  [0]\n",
      "n= 14 pred=  [1] truth=  [1]\n",
      "n= 15 pred=  [0] truth=  [0]\n",
      "n= 16 pred=  [0] truth=  [0]\n",
      "n= 17 pred=  [1] truth=  [1]\n",
      "n= 18 pred=  [0] truth=  [0]\n",
      "n= 19 pred=  [1] truth=  [1]\n",
      "n= 20 pred=  [1] truth=  [1]\n",
      "n= 21 pred=  [0] truth=  [0]\n",
      "n= 22 pred=  [1] truth=  [1]\n",
      "Mean acc=  0.9130434782608695\n",
      "Channels marked as bad: none\n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape= \", epochs_data[pivot:].shape, \"y shape= \", labels[pivot:].shape)\n",
    "\n",
    "scores = []\n",
    "for n in range(epochs_data[pivot:].shape[0]):\n",
    "    pred = clf.predict(epochs_data[pivot:][n:n + 1, :, :])\n",
    "    print(\"n=\", n, \"pred= \", pred, \"truth= \", labels[pivot:][n:n + 1])\n",
    "    scores.append(1 - np.abs(pred[0] - labels[pivot:][n:n + 1][0]))\n",
    "print(\"Mean acc= \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b783fc4e5bd2b2ad5a3f4ecea2f7b0c197a9e63f27d72adb47f4d47cdeb656c5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
